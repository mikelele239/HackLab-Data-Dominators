{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPQgl9TXbFPugdYbd8i6SgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikelele239/HackLab-Data-Dominators/blob/main/Hacklab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing missing values and outliers"
      ],
      "metadata": {
        "id": "h2_AmshCD1Qf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 1.  Basic setup ‚Äì run this cell first in Google Colab\n",
        "# ================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ‚¨áÔ∏è  Adjust path if needed\n",
        "file_path = '/Structured data.csv'\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 2.  Load data\n",
        "# ------------------------------------------------\n",
        "df = pd.read_csv(file_path)\n",
        "print(f\"Loaded shape: {df.shape}\")\n",
        "display(df.head())\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 3.  Quick audit ‚Äì dtypes & obvious issues\n",
        "# ------------------------------------------------\n",
        "print(\"\\nüîé  Raw dtypes\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 4.  ‚ú®  MISSING-VALUE CLEANUP\n",
        "# ------------------------------------------------\n",
        "# ‚Ä¢ Common hidden missings ‚Üí NaN\n",
        "df = df.applymap(lambda x: np.nan if (isinstance(x, str) and str(x).strip() in\n",
        "                                      ['', 'NA', 'N/A', 'na', 'n/a', '?', '-', '‚Äì']) else x)\n",
        "\n",
        "# ‚Ä¢ Coerce ‚Äúobject‚Äù columns to numeric when possible\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == object:\n",
        "        try:\n",
        "            df[col] = pd.to_numeric(df[col])\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "print(\"\\nüßπ  Null counts after coercion:\")\n",
        "display(df.isna().sum())\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 4b.  SPECIAL-CASE: SeniorCitizen AS CATEGORICAL\n",
        "# ------------------------------------------------\n",
        "# Treat the binary flag correctly:\n",
        "if 'SeniorCitizen' in df.columns:\n",
        "    df['SeniorCitizen'] = df['SeniorCitizen'].astype('category')\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 4c.  IMPUTATION: Drop/Fill\n",
        "# ------------------------------------------------\n",
        "thresh = len(df.columns) - 2\n",
        "df = df.dropna(thresh=thresh)\n",
        "\n",
        "# Now pick numeric vs categorical (SeniorCitizen will be in cat_cols)\n",
        "num_cols = [c for c in df.select_dtypes(include=['number']).columns\n",
        "            if c != 'SeniorCitizen']\n",
        "cat_cols = df.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "# Fill missing\n",
        "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
        "df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 5.  ü©π  OUTLIER HANDLING (IQR ‚Äúfence‚Äù method)\n",
        "# ------------------------------------------------\n",
        "def cap_iqr(series, factor=1.5):\n",
        "    \"\"\"Clip values outside [Q1 ‚Äì factor¬∑IQR, Q3 + factor¬∑IQR].\"\"\"\n",
        "    q1, q3 = series.quantile([.25, .75])\n",
        "    iqr = q3 - q1\n",
        "    return series.clip(q1 - factor*iqr, q3 + factor*iqr)\n",
        "\n",
        "# Only apply to true numeric columns (SeniorCitizen is skipped)\n",
        "for col in num_cols:\n",
        "    df[col] = cap_iqr(df[col])\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 6.  ‚úÖ  Tidy output check\n",
        "# ------------------------------------------------\n",
        "print(\"\\nüéâ  Cleaned shape:\", df.shape)\n",
        "print(df.dtypes)\n",
        "display(df.describe(include='all').T)\n",
        "\n",
        "# ------------------------------------------------\n",
        "# 7.  (Optional) Export the cleaned file\n",
        "# ------------------------------------------------\n",
        "clean_fname = 'Structured data_cleaned.csv'\n",
        "df.to_csv(clean_fname, index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(clean_fname)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kub2-QIOlyI3",
        "outputId": "0ac98a9b-49ac-43c1-e052-53b77f0749f8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded shape: (7043, 21)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
              "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
              "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
              "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
              "3  7795-CFOCW    Male              0      No         No      45           No   \n",
              "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
              "0  No phone service             DSL             No  ...               No   \n",
              "1                No             DSL            Yes  ...              Yes   \n",
              "2                No             DSL            Yes  ...               No   \n",
              "3  No phone service             DSL            Yes  ...              Yes   \n",
              "4                No     Fiber optic             No  ...               No   \n",
              "\n",
              "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
              "0          No          No              No  Month-to-month              Yes   \n",
              "1          No          No              No        One year               No   \n",
              "2          No          No              No  Month-to-month              Yes   \n",
              "3         Yes          No              No        One year               No   \n",
              "4          No          No              No  Month-to-month              Yes   \n",
              "\n",
              "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
              "0           Electronic check          29.85         29.85    No  \n",
              "1               Mailed check          56.95        1889.5    No  \n",
              "2               Mailed check          53.85        108.15   Yes  \n",
              "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
              "4           Electronic check          70.70        151.65   Yes  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64842645-0d9e-4047-8f96-0f734a5e80e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>...</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.5</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7795-CFOCW</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>45</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Bank transfer (automatic)</td>\n",
              "      <td>42.30</td>\n",
              "      <td>1840.75</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9237-HQITU</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>70.70</td>\n",
              "      <td>151.65</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64842645-0d9e-4047-8f96-0f734a5e80e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64842645-0d9e-4047-8f96-0f734a5e80e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64842645-0d9e-4047-8f96-0f734a5e80e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c36ffec-0171-4d06-afdc-c4b3b397a38a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c36ffec-0171-4d06-afdc-c4b3b397a38a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c36ffec-0171-4d06-afdc-c4b3b397a38a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîé  Raw dtypes\n",
            "customerID           object\n",
            "gender               object\n",
            "SeniorCitizen         int64\n",
            "Partner              object\n",
            "Dependents           object\n",
            "tenure                int64\n",
            "PhoneService         object\n",
            "MultipleLines        object\n",
            "InternetService      object\n",
            "OnlineSecurity       object\n",
            "OnlineBackup         object\n",
            "DeviceProtection     object\n",
            "TechSupport          object\n",
            "StreamingTV          object\n",
            "StreamingMovies      object\n",
            "Contract             object\n",
            "PaperlessBilling     object\n",
            "PaymentMethod        object\n",
            "MonthlyCharges      float64\n",
            "TotalCharges         object\n",
            "Churn                object\n",
            "dtype: object\n",
            "\n",
            "üßπ  Null counts after coercion:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "customerID           0\n",
              "gender               0\n",
              "SeniorCitizen        0\n",
              "Partner              0\n",
              "Dependents           0\n",
              "tenure               0\n",
              "PhoneService         0\n",
              "MultipleLines        0\n",
              "InternetService      0\n",
              "OnlineSecurity       0\n",
              "OnlineBackup         0\n",
              "DeviceProtection     0\n",
              "TechSupport          0\n",
              "StreamingTV          0\n",
              "StreamingMovies      0\n",
              "Contract             0\n",
              "PaperlessBilling     0\n",
              "PaymentMethod        0\n",
              "MonthlyCharges       0\n",
              "TotalCharges        11\n",
              "Churn                0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>customerID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Partner</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dependents</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tenure</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PhoneService</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultipleLines</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>InternetService</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OnlineBackup</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DeviceProtection</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TechSupport</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StreamingTV</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StreamingMovies</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Contract</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PaymentMethod</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TotalCharges</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Churn</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéâ  Cleaned shape: (7043, 21)\n",
            "customerID            object\n",
            "gender                object\n",
            "SeniorCitizen       category\n",
            "Partner               object\n",
            "Dependents            object\n",
            "tenure                 int64\n",
            "PhoneService          object\n",
            "MultipleLines         object\n",
            "InternetService       object\n",
            "OnlineSecurity        object\n",
            "OnlineBackup          object\n",
            "DeviceProtection      object\n",
            "TechSupport           object\n",
            "StreamingTV           object\n",
            "StreamingMovies       object\n",
            "Contract              object\n",
            "PaperlessBilling      object\n",
            "PaymentMethod         object\n",
            "MonthlyCharges       float64\n",
            "TotalCharges         float64\n",
            "Churn                 object\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   count unique               top    freq         mean  \\\n",
              "customerID          7043   7043        3186-AJIEK       1          NaN   \n",
              "gender              7043      2              Male    3555          NaN   \n",
              "SeniorCitizen     7043.0    2.0               0.0  5901.0          NaN   \n",
              "Partner             7043      2                No    3641          NaN   \n",
              "Dependents          7043      2                No    4933          NaN   \n",
              "tenure            7043.0    NaN               NaN     NaN    32.371149   \n",
              "PhoneService        7043      2               Yes    6361          NaN   \n",
              "MultipleLines       7043      3                No    3390          NaN   \n",
              "InternetService     7043      3       Fiber optic    3096          NaN   \n",
              "OnlineSecurity      7043      3                No    3498          NaN   \n",
              "OnlineBackup        7043      3                No    3088          NaN   \n",
              "DeviceProtection    7043      3                No    3095          NaN   \n",
              "TechSupport         7043      3                No    3473          NaN   \n",
              "StreamingTV         7043      3                No    2810          NaN   \n",
              "StreamingMovies     7043      3                No    2785          NaN   \n",
              "Contract            7043      3    Month-to-month    3875          NaN   \n",
              "PaperlessBilling    7043      2               Yes    4171          NaN   \n",
              "PaymentMethod       7043      4  Electronic check    2365          NaN   \n",
              "MonthlyCharges    7043.0    NaN               NaN     NaN    64.761692   \n",
              "TotalCharges      7043.0    NaN               NaN     NaN  2281.916928   \n",
              "Churn               7043      2                No    5174          NaN   \n",
              "\n",
              "                          std    min      25%       50%     75%     max  \n",
              "customerID                NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "gender                    NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "SeniorCitizen             NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "Partner                   NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "Dependents                NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "tenure              24.559481    0.0      9.0      29.0    55.0    72.0  \n",
              "PhoneService              NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "MultipleLines             NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "InternetService           NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "OnlineSecurity            NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "OnlineBackup              NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "DeviceProtection          NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "TechSupport               NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "StreamingTV               NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "StreamingMovies           NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "Contract                  NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "PaperlessBilling          NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "PaymentMethod             NaN    NaN      NaN       NaN     NaN     NaN  \n",
              "MonthlyCharges      30.090047  18.25     35.5     70.35   89.85  118.75  \n",
              "TotalCharges      2265.270398   18.8  402.225  1397.475  3786.6  8684.8  \n",
              "Churn                     NaN    NaN      NaN       NaN     NaN     NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-685f416a-3bb6-4563-83f7-0b0231cf63ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>customerID</th>\n",
              "      <td>7043</td>\n",
              "      <td>7043</td>\n",
              "      <td>3186-AJIEK</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender</th>\n",
              "      <td>7043</td>\n",
              "      <td>2</td>\n",
              "      <td>Male</td>\n",
              "      <td>3555</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <td>7043.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5901.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Partner</th>\n",
              "      <td>7043</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>3641</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dependents</th>\n",
              "      <td>7043</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>4933</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tenure</th>\n",
              "      <td>7043.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.371149</td>\n",
              "      <td>24.559481</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PhoneService</th>\n",
              "      <td>7043</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>6361</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultipleLines</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>3390</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>InternetService</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>Fiber optic</td>\n",
              "      <td>3096</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>3498</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OnlineBackup</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>3088</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DeviceProtection</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>3095</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TechSupport</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>3473</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StreamingTV</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>2810</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>StreamingMovies</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>2785</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Contract</th>\n",
              "      <td>7043</td>\n",
              "      <td>3</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>3875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <td>7043</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>4171</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PaymentMethod</th>\n",
              "      <td>7043</td>\n",
              "      <td>4</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>2365</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <td>7043.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64.761692</td>\n",
              "      <td>30.090047</td>\n",
              "      <td>18.25</td>\n",
              "      <td>35.5</td>\n",
              "      <td>70.35</td>\n",
              "      <td>89.85</td>\n",
              "      <td>118.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TotalCharges</th>\n",
              "      <td>7043.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2281.916928</td>\n",
              "      <td>2265.270398</td>\n",
              "      <td>18.8</td>\n",
              "      <td>402.225</td>\n",
              "      <td>1397.475</td>\n",
              "      <td>3786.6</td>\n",
              "      <td>8684.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Churn</th>\n",
              "      <td>7043</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>5174</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-685f416a-3bb6-4563-83f7-0b0231cf63ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-685f416a-3bb6-4563-83f7-0b0231cf63ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-685f416a-3bb6-4563-83f7-0b0231cf63ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bb342e74-67fa-48cb-9900-95e892581e6f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb342e74-67fa-48cb-9900-95e892581e6f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bb342e74-67fa-48cb-9900-95e892581e6f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"files\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"7043\",\n        \"max\": \"7043\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"7043\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 2,\n        \"max\": 7043,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"freq\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1\",\n        \"max\": \"6361\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 32.37114865824223,\n        \"max\": 2281.9169281556156,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          32.37114865824223\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 24.55948102309423,\n        \"max\": 2265.2703984821865,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          24.55948102309423\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.0,\n        \"max\": 18.8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 9.0,\n        \"max\": 402.225,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 29.0,\n        \"max\": 1397.475,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          29.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 55.0,\n        \"max\": 3786.6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          55.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 72.0,\n        \"max\": 8684.8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          72.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d4ee6d61-adb3-414e-9887-67a03622ecc2\", \"Structured data_cleaned.csv\", 971966)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature engineering"
      ],
      "metadata": {
        "id": "7dKqRRDDxn5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "# ‚îÇ 1 ) Upload raw file                               ‚îÇ\n",
        "# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "uploaded = files.upload()  # UI prompt (drag‚Äëand‚Äëdrop or file picker)\n",
        "if not uploaded:\n",
        "    raise ValueError(\"No file selected ‚Äì please upload a CSV or Excel document.\")\n",
        "raw_name = next(iter(uploaded))  # first/only uploaded filename\n",
        "# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "# ‚îÇ 2 ) Load into DataFrame                            ‚îÇ\n",
        "# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "if raw_name.lower().endswith(\".csv\"):\n",
        "    df = pd.read_csv(raw_name)\n",
        "elif raw_name.lower().endswith((\".xls\", \".xlsx\")):\n",
        "    df = pd.read_excel(raw_name)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported file type ‚Äì please upload .csv, .xls, or .xlsx\")\n",
        "# Ensure critical numeric columns are numeric (TotalCharges sometimes ships as object)\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "# ‚îÇ 3 ) Feature engineering                            ‚îÇ\n",
        "# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "# 3.1 Average monthly spend\n",
        "#     (protect from divide‚Äëby‚Äëzero when tenure==0)\n",
        "df[\"avg_monthly_spend\"] = df[\"TotalCharges\"] / df[\"tenure\"].replace(0, np.nan)\n",
        "df[\"avg_monthly_spend\"].fillna(0, inplace=True)\n",
        "# 3.2 Spend variance (trend)\n",
        "df[\"spend_diff\"] = df[\"MonthlyCharges\"] - df[\"avg_monthly_spend\"]\n",
        "# 3.3 Tenure bucket\n",
        "bins = [0, 12, 24, 48, np.inf]\n",
        "labels = [\"0-12 months\", \"13-24 months\", \"25-48 months\", \"49+ months\"]\n",
        "df[\"tenure_bucket\"] = pd.cut(df[\"tenure\"], bins=bins, labels=labels, right=True, include_lowest=True)\n",
        "# 3.4 Auto‚Äëpayment flag\n",
        "df[\"auto_pay\"] = df[\"PaymentMethod\"].str.contains(\"automatic\", case=False, na=False).astype(int)\n",
        "# 3.5 Total services subscribed\n",
        "service_cols = [\n",
        "    \"PhoneService\",\n",
        "    \"InternetService\",      # counts as 1 if NOT \"No\"\n",
        "    \"OnlineSecurity\",\n",
        "    \"OnlineBackup\",\n",
        "    \"DeviceProtection\",\n",
        "    \"TechSupport\",\n",
        "    \"StreamingTV\",\n",
        "    \"StreamingMovies\",\n",
        "]\n",
        "def summed_services(row):\n",
        "    total = 0\n",
        "    for col in service_cols:\n",
        "        val = str(row[col]).strip().lower()\n",
        "        if col == \"InternetService\":\n",
        "            total += 0 if val == \"no\" else 1\n",
        "        else:\n",
        "            total += 1 if val == \"yes\" else 0\n",
        "    return total\n",
        "df[\"total_services_subscribed\"] = df.apply(summed_services, axis=1)\n",
        "# 3.6 High‚Äëspender flag\n",
        "threshold = df[\"MonthlyCharges\"].mean() + df[\"MonthlyCharges\"].std()\n",
        "df[\"high_spender\"] = (df[\"MonthlyCharges\"] > threshold).astype(int)\n",
        "# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "# ‚îÇ 4 ) Re‚Äëorder so churn sits last                    ‚îÇ\n",
        "# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "if \"Churn\" in df.columns:\n",
        "    ordered_cols = [c for c in df.columns if c != \"Churn\"] + [\"Churn\"]\n",
        "    df = df[ordered_cols]\n",
        "# ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "# ‚îÇ 5 ) Save & trigger download                        ‚îÇ\n",
        "# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "output_name = f\"processed_{raw_name.rsplit('.', 1)[0]}.csv\"\n",
        "df.to_csv(output_name, index=False)\n",
        "files.download(output_name)\n",
        "print(f\"‚úÖ Done! Your processed file is downloading as ‚ûú {output_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "collapsed": true,
        "id": "T4rxSfv1xqqc",
        "outputId": "ef592169-0dde-4c89-b666-cd71fa1417bc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-702d2265-2c54-4eb0-a744-f621539fc86c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-702d2265-2c54-4eb0-a744-f621539fc86c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2. Cleaned data.csv to 2. Cleaned data (3).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab825988-b96b-4917-8e23-b1f2300de22a\", \"processed_2. Cleaned data (3).csv\", 1327566)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done! Your processed file is downloading as ‚ûú processed_2. Cleaned data (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM sentiment analysis"
      ],
      "metadata": {
        "id": "oBB7DhaiRTWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import files\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "# 3. Upload your workbook\n",
        "print(\"üìÅ Upload your 'Unstructured data.xlsx':\")\n",
        "uploaded = files.upload()\n",
        "file_name = next(iter(uploaded))\n",
        "\n",
        "# 4. Read it\n",
        "df = pd.read_excel(file_name)\n",
        "print(\"‚úÖ Columns found:\", df.columns.tolist())\n",
        "\n",
        "# 5. üîë Put your key here and init client\n",
        "os.environ[\"API_KEY\"] = \"AIzaSyAkO2ZZmmJCAwmUsyrBn11vpk1zFVXQADA\"   # ‚Üê REPLACE with your Google API key\n",
        "client = genai.Client(api_key=os.environ[\"API_KEY\"])\n",
        "\n",
        "# 6. Complaint column\n",
        "complaint_column = \"complaint\"\n",
        "\n",
        "# 7a. Helper: split into chunks of size N\n",
        "def chunk_list(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i : i + n]\n",
        "\n",
        "# 7b. Batched sentiment rating\n",
        "def rate_sentiments_batched(texts, batch_size=20, rpm=15):\n",
        "    all_scores = []\n",
        "    delay = 60.0 / rpm\n",
        "    for batch in chunk_list(texts, batch_size):\n",
        "        numbered = \"\\n\".join(f\"{i+1}. {txt}\" for i, txt in enumerate(batch))\n",
        "        prompt = (\n",
        "            \"Rate the anger level of each of the following customer complaints on a scale \"\n",
        "            \"from 1 (neutral/mild) to 5 (very angry). Answer with only the numbers separated \"\n",
        "            \"by commas, in order.\\n\\n\"\n",
        "            f\"{numbered}\"\n",
        "        )\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            contents=prompt,\n",
        "            config=types.GenerateContentConfig(temperature=0)\n",
        "        )\n",
        "        text = resp.text.strip()\n",
        "        try:\n",
        "            scores = [int(x) for x in text.split(\",\")]\n",
        "            if len(scores) != len(batch):\n",
        "                raise ValueError(f\"{len(scores)}‚â†{len(batch)}\")\n",
        "        except Exception:\n",
        "            # Fallback to single calls if parse fails\n",
        "            scores = [rate_sentiment(t) for t in batch]\n",
        "        all_scores.extend(scores)\n",
        "        time.sleep(delay)   # <-- now works\n",
        "    return all_scores\n",
        "\n",
        "# 8. Apply batched rating\n",
        "print(f\"üîç Rating '{complaint_column}' in batches‚Ä¶\")\n",
        "texts = df[complaint_column].astype(str).tolist()\n",
        "df[\"Sentiment_Score\"] = rate_sentiments_batched(texts)\n",
        "\n",
        "# 9. Save & download\n",
        "out = \"with_sentiment.xlsx\"\n",
        "df.to_excel(out, index=False)\n",
        "print(\"‚úÖ Done:\", out)\n",
        "files.download(out)\n",
        "\n",
        "\n",
        "# 3. Upload your workbook\n",
        "print(\"üìÅ Upload your 'Unstructured data.xlsx':\")\n",
        "uploaded = files.upload()\n",
        "file_name = next(iter(uploaded))\n",
        "\n",
        "# 4. Read it\n",
        "df = pd.read_excel(file_name)\n",
        "print(\"‚úÖ Columns found:\", df.columns.tolist())\n",
        "\n",
        "# 5. üîë Put your key here and init client\n",
        "os.environ[\"API_KEY\"] = \"AIzaSyAkO2ZZmmJCAwmUsyrBn11vpk1zFVXQADA\"   # ‚Üê REPLACE with your Google API key\n",
        "client = genai.Client(api_key=os.environ[\"API_KEY\"])  # ‚Üê instantiate the Gemini client :contentReference[oaicite:1]{index=1}\n",
        "\n",
        "# 6. Complaint column\n",
        "complaint_column = \"complaint\"\n",
        "\n",
        "# 7a. Helper: split into chunks of size N\n",
        "def chunk_list(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i : i + n]\n",
        "\n",
        "# 7b. Batched sentiment rating\n",
        "def rate_sentiments_batched(texts, batch_size=20, rpm=15):\n",
        "    \"\"\"\n",
        "    Returns a list of ints, one per text in 'texts', rating anger 1‚Äì5.\n",
        "    Respects at most 'rpm' requests per minute.\n",
        "    \"\"\"\n",
        "    all_scores = []\n",
        "    delay = 60.0 / rpm\n",
        "    for batch in chunk_list(texts, batch_size):\n",
        "        # build numbered prompt\n",
        "        numbered = \"\\n\".join(f\"{i+1}. {txt}\" for i, txt in enumerate(batch))\n",
        "        prompt = (\n",
        "            \"Rate the anger level of each of the following customer complaints on a scale \"\n",
        "            \"from 1 (neutral/mild) to 5 (very angry). \"\n",
        "            \"Answer with only the numbers separated by commas, in order.\\n\\n\"\n",
        "            f\"{numbered}\"\n",
        "        )\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            contents=prompt,\n",
        "            config=types.GenerateContentConfig(temperature=0)\n",
        "        )\n",
        "        # parse ‚Äú1,2,3,1,5‚Äù ‚Üí [1,2,3,1,5]\n",
        "        text = resp.text.strip()\n",
        "        try:\n",
        "            scores = [int(x) for x in text.split(\",\")]\n",
        "            if len(scores) != len(batch):\n",
        "                raise ValueError(f\"{len(scores)}‚â†{len(batch)}\")\n",
        "        except Exception:\n",
        "            # fallback: one-by-one (slower) if parsing fails\n",
        "            scores = [rate_sentiment(t) for t in batch]\n",
        "        all_scores.extend(scores)\n",
        "        # throttle\n",
        "        time.sleep(delay)\n",
        "    return all_scores\n",
        "\n",
        "# 8. Apply batched rating\n",
        "print(f\"üîç Rating '{complaint_column}' in batches‚Ä¶\")\n",
        "texts = df[complaint_column].astype(str).tolist()\n",
        "df[\"Sentiment_Score\"] = rate_sentiments_batched(texts)\n",
        "\n",
        "# 9. Save & download\n",
        "out = \"with_sentiment.xlsx\"\n",
        "df.to_excel(out, index=False)\n",
        "print(\"‚úÖ Done:\", out)\n",
        "files.download(out)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pUgw8dHkRhHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM category analysis"
      ],
      "metadata": {
        "id": "pc4ME7gOiO8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import files\n",
        "\n",
        "# 3. Upload your workbook\n",
        "print(\"üìÅ Upload your 'Unstructured data.xlsx':\")\n",
        "uploaded = files.upload()\n",
        "file_name = next(iter(uploaded))\n",
        "\n",
        "# 4. Read it\n",
        "df = pd.read_excel(file_name)\n",
        "print(\"‚úÖ Columns found:\", df.columns.tolist())\n",
        "\n",
        "# 5. üîë Put your key here and init client\n",
        "os.environ[\"API_KEY\"] = \"AIzaSyAkO2ZZmmJCAwmUsyrBn11vpk1zFVXQADA\"\n",
        "client = genai.Client(api_key=os.environ[\"API_KEY\"])\n",
        "\n",
        "# 6. Complaint column name\n",
        "COMPLAINT_COL = \"complaint\"\n",
        "\n",
        "# 7. Helper: split into chunks of size N\n",
        "def chunk_list(lst, n):\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i : i + n]\n",
        "\n",
        "# 8. STEP 1 ‚Äì Generate up to 10 one-word categories\n",
        "all_texts = df[COMPLAINT_COL].astype(str).tolist()\n",
        "prompt = (\n",
        "    \"You are given a list of customer complaints. \"\n",
        "    \"Please identify up to 10 broad one-word categories that cover these \"\n",
        "    \"complaints (e.g., 'Billing', 'Service', 'Quality', etc.). \"\n",
        "    \"Answer with only the category words, separated by commas, in lowercase.\"\n",
        "    \"\\n\\n\"\n",
        "    + \"\\n\".join(f\"- {t}\" for t in all_texts)\n",
        ")\n",
        "resp = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    contents=prompt,\n",
        "    config=types.GenerateContentConfig(temperature=0)\n",
        ")\n",
        "cats_text = resp.text.strip()\n",
        "categories = [c.strip() for c in cats_text.split(\",\")]\n",
        "print(\"üè∑Ô∏è Categories:\", categories)\n",
        "\n",
        "# 9. STEP 2 ‚Äì Batched categorization using same 20√ó/15 rpm rate limits\n",
        "def categorize_batched(texts, categories, batch_size=20, rpm=15):\n",
        "    delay = 60.0 / rpm\n",
        "    all_labels = []\n",
        "    for batch in chunk_list(texts, batch_size):\n",
        "        numbered = \"\\n\".join(f\"{i+1}. {txt}\" for i, txt in enumerate(batch))\n",
        "        prompt = (\n",
        "            f\"Given these categories: {', '.join(categories)}\\n\\n\"\n",
        "            \"Assign each customer complaint to the single best matching category. \"\n",
        "            \"Answer with only the category word for each complaint, in order, \"\n",
        "            \"separated by commas.\\n\\n\"\n",
        "            f\"{numbered}\"\n",
        "        )\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            contents=prompt,\n",
        "            config=types.GenerateContentConfig(temperature=0)\n",
        "        )\n",
        "        text = resp.text.strip()\n",
        "        # parse and fallback if needed\n",
        "        labels = [lbl.strip().lower() for lbl in text.split(\",\")]\n",
        "        if len(labels) != len(batch):\n",
        "            # fallback to one-by-one if parse fails\n",
        "            labels = []\n",
        "            for txt in batch:\n",
        "                r = client.models.generate_content(\n",
        "                    model=\"gemini-2.0-flash\",\n",
        "                    contents=(\n",
        "                        f\"Categories: {', '.join(categories)}\\n\\n\"\n",
        "                        f\"Complaint: {txt}\\n\\n\"\n",
        "                        \"Assign the single best category. Answer with only the word.\"\n",
        "                    ),\n",
        "                    config=types.GenerateContentConfig(temperature=0)\n",
        "                )\n",
        "                labels.append(r.text.strip().lower())\n",
        "        all_labels.extend(labels)\n",
        "        time.sleep(delay)\n",
        "    return all_labels\n",
        "\n",
        "print(\"üîç Categorizing complaints in batches‚Ä¶\")\n",
        "labels = categorize_batched(all_texts, categories)\n",
        "df[\"category\"] = labels\n",
        "\n",
        "# 10. Move 'category' to be the leftmost column\n",
        "cols = [\"category\"] + [c for c in df.columns if c != \"category\"]\n",
        "df = df[cols]\n",
        "\n",
        "# 11. Save & download\n",
        "out = \"with_categories.xlsx\"\n",
        "df.to_excel(out, index=False)\n",
        "print(\"‚úÖ Done:\", out)\n",
        "files.download(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "2v9L1k2biWTX",
        "outputId": "9202b86e-253b-43d7-9d3b-c9c7f2d80f95"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Upload your 'Unstructured data.xlsx':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-13633fb0-8a47-421a-b5f8-31a70467fd51\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-13633fb0-8a47-421a-b5f8-31a70467fd51\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Unstructured data.xlsx to Unstructured data (9).xlsx\n",
            "‚úÖ Columns found: ['customerID', 'complaint', 'complaint_number']\n",
            "üè∑Ô∏è Categories: ['connectivity', 'service', 'billing', 'speed', 'support', 'streaming', 'quality', 'reliability', 'value', 'phone']\n",
            "üîç Categorizing complaints in batches‚Ä¶\n",
            "‚úÖ Done: with_categories.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_40f6c8cd-8299-4fbf-8abc-949eed779ade\", \"with_categories.xlsx\", 105367)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data type merge"
      ],
      "metadata": {
        "id": "w3FiJXgPpAid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 1Ô∏è‚É£  Upload the structured dataset (Dataset‚ÄØ3)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"‚¨ÜÔ∏è  Please upload Dataset‚ÄØ3 (structured CSV, e.g. 'Feature engineered data.csv'):\")\n",
        "up_struct = files.upload()\n",
        "struct_name = next(iter(up_struct))               # first uploaded filename\n",
        "df_struct = pd.read_csv(io.BytesIO(up_struct[struct_name]))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2Ô∏è‚É£  Upload the unstructured dataset (Dataset‚ÄØ4)\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\n‚¨ÜÔ∏è  Please upload Dataset‚ÄØ4 (unstructured XLSX, e.g. 'with_categories_and_sentiment.xlsx'):\")\n",
        "up_unstr = files.upload()\n",
        "unstr_name = next(iter(up_unstr))\n",
        "df_unstr  = pd.read_excel(io.BytesIO(up_unstr[unstr_name]))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 3Ô∏è‚É£  Normalise the key column name\n",
        "#     (works whether it is 'customerID' or 'customer_id')\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "for df in (df_struct, df_unstr):\n",
        "    if \"customer_id\" in df.columns:\n",
        "        df.rename(columns={\"customer_id\": \"customerID\"}, inplace=True)\n",
        "\n",
        "key = \"customerID\"   # unified primary key\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 4Ô∏è‚É£  Feature‚Äëengineer the unstructured data\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "#   ‚Ä¢ Average sentiment score\n",
        "#   ‚Ä¢ Number of complaints\n",
        "agg = (df_unstr\n",
        "       .groupby(key, as_index=False)\n",
        "       .agg(avg_sentiment      = (\"Sentiment_Score\", \"mean\"),\n",
        "            num_complaints     = (\"complaint\",       \"count\")))\n",
        "\n",
        "#   ‚Ä¢ Most prevalent complaint category\n",
        "cat_stats = (df_unstr\n",
        "             .groupby([key, \"category\"])\n",
        "             .agg(freq          = (\"category\",        \"size\"),\n",
        "                  avg_sent_cat  = (\"Sentiment_Score\", \"mean\"))\n",
        "             .reset_index())\n",
        "\n",
        "# Select the category with\n",
        "#   1) highest frequency\n",
        "#   2) if tied ‚Üí higher avg_sent_cat (5 = more negative)\n",
        "cat_stats.sort_values([\"freq\", \"avg_sent_cat\"], ascending=[False, False], inplace=True)\n",
        "best_cat = (cat_stats\n",
        "            .drop_duplicates(subset=key, keep=\"first\")\n",
        "            .loc[:, [key, \"category\"]]\n",
        "            .rename(columns={\"category\": \"prev_complaint_category\"}))\n",
        "\n",
        "# Combine the three engineered features\n",
        "features = agg.merge(best_cat, on=key, how=\"outer\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 5Ô∏è‚É£  Merge with the structured data\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "df_merged = df_struct.merge(features, on=key, how=\"left\")\n",
        "\n",
        "# Fill NaNs (no unstructured data) with None\n",
        "df_merged[[\"avg_sentiment\", \"num_complaints\", \"prev_complaint_category\"]] = (\n",
        "    df_merged[[\"avg_sentiment\", \"num_complaints\", \"prev_complaint_category\"]].where(\n",
        "        df_merged[[\"avg_sentiment\", \"num_complaints\", \"prev_complaint_category\"]].notna(), None)\n",
        ")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 6Ô∏è‚É£  Ensure the Churn column is last\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "churn_col = next((c for c in df_merged.columns if c.lower() == \"churn\"), None)\n",
        "if churn_col:\n",
        "    reordered = [c for c in df_merged.columns if c != churn_col] + [churn_col]\n",
        "    df_merged = df_merged[reordered]\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 7Ô∏è‚É£  Download the result\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "out_file = \"dataset3_with_unstructured_features.csv\"\n",
        "df_merged.to_csv(out_file, index=False)\n",
        "files.download(out_file)          # triggers browser download\n",
        "print(f\"\\n‚úÖ  Finished!  '{out_file}' is downloading‚Ä¶\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "collapsed": true,
        "id": "85IwCeg7pMUV",
        "outputId": "92e6a885-1afe-4ba2-cfdd-7e685bd3986c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨ÜÔ∏è  Please upload Dataset‚ÄØ3 (structured CSV, e.g. 'Feature engineered data.csv'):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03db3464-5e2b-42c3-a88b-d287a928694b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03db3464-5e2b-42c3-a88b-d287a928694b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 3. Feature engineered data.csv to 3. Feature engineered data (10).csv\n",
            "\n",
            "‚¨ÜÔ∏è  Please upload Dataset‚ÄØ4 (unstructured XLSX, e.g. 'with_categories_and_sentiment.xlsx'):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5dd5d79-7ac2-4948-b893-43f284cac6bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5dd5d79-7ac2-4948-b893-43f284cac6bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 4. with_categories_and_sentiment.xlsx to 4. with_categories_and_sentiment.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dfad31fd-ec41-4654-948f-eead07bab87c\", \"dataset3_with_unstructured_features.csv\", 1355594)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ  Finished!  'dataset3_with_unstructured_features.csv' is downloading‚Ä¶\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 1Ô∏è‚É£  Upload the merged dataset to be fixed\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "print(\"‚¨ÜÔ∏è  Please upload your merged CSV (e.g. 'dataset3_with_unstructured_features.csv'):\")\n",
        "up = files.upload()\n",
        "fname = next(iter(up))\n",
        "df = pd.read_csv(io.BytesIO(up[fname]))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 2Ô∏è‚É£  Replace None with NaN so pandas detects missing\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "df = df.replace({None: np.nan})\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 3Ô∏è‚É£  Impute numeric features\n",
        "#    ‚Ä¢ avg_sentiment ‚Üí 1\n",
        "#    ‚Ä¢ num_complaints ‚Üí 0\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "df[\"avg_sentiment\"].fillna(1, inplace=True)\n",
        "df[\"num_complaints\"].fillna(0, inplace=True)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 4Ô∏è‚É£  Impute categorical feature\n",
        "#    ‚Ä¢ prev_complaint_category ‚Üí \"No_complaint\"\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "df[\"prev_complaint_category\"].fillna(\"No_complaint\", inplace=True)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 5Ô∏è‚É£  Move the churn column to the end\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "churn_col = next((c for c in df.columns if c.lower() == \"churn\"), None)\n",
        "if churn_col:\n",
        "    cols = [c for c in df.columns if c != churn_col] + [churn_col]\n",
        "    df = df[cols]\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# 6Ô∏è‚É£  Save and trigger download\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "out_name = fname.replace(\".csv\", \"_imputed.csv\")\n",
        "df.to_csv(out_name, index=False)\n",
        "files.download(out_name)\n",
        "\n",
        "print(f\"\\n‚úÖ  Imputation complete. Downloading '{out_name}'‚Ä¶\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "DeBsU73JvIQ1",
        "outputId": "444fa90b-c157-42c8-ba78-513c9fe9b75a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚¨ÜÔ∏è  Please upload your merged CSV (e.g. 'dataset3_with_unstructured_features.csv'):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3070fb70-5479-41b1-ab25-0c97bc33369d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3070fb70-5479-41b1-ab25-0c97bc33369d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Data final .csv to Data final  (2).csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ae343f7d-c3ba-42f9-93b4-5520e39666f7\", \"Data final  (2)_imputed.csv\", 1469433)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ  Imputation complete. Downloading 'Data final  (2)_imputed.csv'‚Ä¶\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature encoding - Logistic regression\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BRclkWY01vkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Encoding Pipeline for Telco Churn Dataset\n",
        "# --------------------------------------------------\n",
        "# This script runs in Google Colab. It will:\n",
        "#   1. Prompt you to upload a CSV file (your feature-engineered Telco churn data).\n",
        "#   2. Drop non-predictive ID columns (customizable).\n",
        "#   3. One-Hot Encode all categorical features.\n",
        "#   4. Scale numerical features with either StandardScaler or MinMaxScaler.\n",
        "#   5. Output an encoded CSV and trigger a browser download.\n",
        "# --------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
        "import sklearn\n",
        "from packaging import version\n",
        "\n",
        "# ------------------ USER SETTINGS ------------------\n",
        "# Select which scaler to apply on numeric features: 'standard' or 'minmax'\n",
        "scaler_choice = 'standard'  # <-- change to 'minmax' if preferred\n",
        "\n",
        "# Column that should be dropped as non-predictive (e.g., ID columns)\n",
        "id_columns = ['customerID']  # <-- add any additional ID columns here\n",
        "\n",
        "# The name of your target column (if present in the data)\n",
        "# Set to None if your data doesn't include the target yet\n",
        "target_column = None  # <-- change to your target column name if present (e.g., 'Churn')\n",
        "# ---------------------------------------------------\n",
        "\n",
        "# 1Ô∏è‚É£  Upload the data -------------------------------------------------------\n",
        "print(\"Please choose the CSV file you want to encode...\")\n",
        "uploaded = files.upload()\n",
        "if len(uploaded) == 0:\n",
        "    raise RuntimeError(\"No file was uploaded ‚Äî please try again.\")\n",
        "filename = next(iter(uploaded))  # first (and usually only) uploaded file\n",
        "print(f\"\\nLoaded ‚ü∂ {filename}\")\n",
        "\n",
        "# 2Ô∏è‚É£  Read the CSV ----------------------------------------------------------\n",
        "df = pd.read_csv(filename)\n",
        "print(f\"Original shape: {df.shape}\")\n",
        "print(f\"Column names: {df.columns.tolist()}\")\n",
        "\n",
        "# 3Ô∏è‚É£  Drop the key columns --------------------------------------------------\n",
        "for id_col in id_columns:\n",
        "    if id_col in df.columns:\n",
        "        df.drop(columns=[id_col], inplace=True)\n",
        "        print(f\"Dropped column '{id_col}'.\")\n",
        "    else:\n",
        "        print(f\"Column '{id_col}' not found ‚Äî nothing dropped.\")\n",
        "\n",
        "# 4Ô∏è‚É£  Identify feature types automatically ---------------------------------\n",
        "if target_column is not None and target_column not in df.columns:\n",
        "    print(f\"WARNING: Target column '{target_column}' not found in the data!\")\n",
        "    print(f\"Available columns are: {df.columns.tolist()}\")\n",
        "    print(\"Continuing without target column...\")\n",
        "    target_column = None\n",
        "\n",
        "# Get categorical columns (excluding target)\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
        "if target_column and target_column in categorical_cols:\n",
        "    categorical_cols.remove(target_column)\n",
        "\n",
        "# Get numeric columns (excluding target)\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "if target_column and target_column in numeric_cols:\n",
        "    numeric_cols.remove(target_column)\n",
        "\n",
        "# Try to convert columns that might be numeric but stored as strings\n",
        "for col in df.columns:\n",
        "    if col != target_column and col not in categorical_cols + numeric_cols:\n",
        "        try:\n",
        "            # Try to convert to numeric\n",
        "            df[col] = pd.to_numeric(df[col], errors='raise')\n",
        "            numeric_cols.append(col)\n",
        "            print(f\"Converted '{col}' to numeric type.\")\n",
        "        except (ValueError, TypeError):\n",
        "            categorical_cols.append(col)\n",
        "            print(f\"Treating '{col}' as categorical.\")\n",
        "\n",
        "print(\"\\nDetected categorical features:\", categorical_cols)\n",
        "print(\"Detected numeric features:\", numeric_cols)\n",
        "\n",
        "# 5Ô∏è‚É£  Build the preprocessing pipeline --------------------------------------\n",
        "# Skip processing if no features of a particular type\n",
        "transformers = []\n",
        "\n",
        "if categorical_cols:\n",
        "    # Handle OneHotEncoder \"sparse\"/\"sparse_output\" API change (sklearn >=1.2)\n",
        "    ohe_kwargs = dict(handle_unknown='ignore')\n",
        "    if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
        "        ohe_kwargs['sparse_output'] = False\n",
        "    else:\n",
        "        ohe_kwargs['sparse'] = False\n",
        "\n",
        "    transformers.append(('cat', OneHotEncoder(**ohe_kwargs), categorical_cols))\n",
        "\n",
        "if numeric_cols:\n",
        "    scaler = StandardScaler() if scaler_choice.lower() == 'standard' else MinMaxScaler()\n",
        "    transformers.append(('num', scaler, numeric_cols))\n",
        "\n",
        "# Create the column transformer\n",
        "preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
        "\n",
        "# 6Ô∏è‚É£  Fit-transform the data -------------------------------------------------\n",
        "# Separate features and target if target exists\n",
        "X = df.drop(columns=[target_column]) if target_column and target_column in df.columns else df\n",
        "y = df[target_column].copy() if target_column and target_column in df.columns else None\n",
        "\n",
        "# Apply preprocessing\n",
        "X_encoded = preprocessor.fit_transform(X)\n",
        "\n",
        "# Generate feature names for the encoded dataframe\n",
        "feature_names = []\n",
        "if categorical_cols:\n",
        "    # Get the one-hot encoded feature names\n",
        "    cat_transformer_idx = [i for i, (name, _, _) in enumerate(transformers) if name == 'cat'][0]\n",
        "    cat_feature_names = preprocessor.transformers_[cat_transformer_idx][1].get_feature_names_out(categorical_cols)\n",
        "    feature_names.extend(cat_feature_names)\n",
        "\n",
        "if numeric_cols:\n",
        "    # Add the scaled numeric feature names\n",
        "    feature_names.extend(numeric_cols)\n",
        "\n",
        "# Create dataframe with encoded features\n",
        "encoded_df = pd.DataFrame(X_encoded, columns=feature_names)\n",
        "\n",
        "# Add back the target column if it exists\n",
        "if y is not None:\n",
        "    encoded_df[target_column] = y.values\n",
        "    print(f\"Added target column '{target_column}'\")\n",
        "\n",
        "print(\"\\nEncoded shape:\", encoded_df.shape)\n",
        "\n",
        "# 7Ô∏è‚É£  Save & trigger download ----------------------------------------------\n",
        "output_file = 'encoded_churn_features.csv'\n",
        "encoded_df.to_csv(output_file, index=False)\n",
        "print(f\"Saved encoded data ‚ûú {output_file}\")\n",
        "\n",
        "files.download(output_file)\n",
        "print(\"Download should begin automatically ‚úàÔ∏è\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "1velBQux10Yj",
        "outputId": "89fd2c60-f6d7-4f6b-bd81-aa1d367e1699"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please choose the CSV file you want to encode...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2776975e-4ada-4c6d-a9d7-4ed78e707942\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2776975e-4ada-4c6d-a9d7-4ed78e707942\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 3. Feature engineered data.csv to 3. Feature engineered data (9).csv\n",
            "\n",
            "Loaded ‚ü∂ 3. Feature engineered data (9).csv\n",
            "Original shape: (7043, 23)\n",
            "Column names: ['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'AvgChargePerMonth', 'ExtraServicesCount', 'Churn']\n",
            "Dropped column 'customerID'.\n",
            "\n",
            "Detected categorical features: ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'Churn']\n",
            "Detected numeric features: ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges', 'AvgChargePerMonth', 'ExtraServicesCount']\n",
            "\n",
            "Encoded shape: (7043, 49)\n",
            "Saved encoded data ‚ûú encoded_churn_features.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d03bf040-1424-4ca5-b749-4b1af363478e\", \"encoded_churn_features.csv\", 1929187)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download should begin automatically ‚úàÔ∏è\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "szzxVLJazI2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Churn Prediction Pipeline (Google¬†Colab‚Äëready)\n",
        "# =================================================\n",
        "# ‚ú® Enhancements (May‚ÄØ2025)\n",
        "# ‚Ä¢ **Removed** hard 95‚ÄØ% accuracy goal ‚Äì the pipeline now always reports metrics without threshold‚Äëgating.\n",
        "# ‚Ä¢ **NEW** Top‚Äë3 churn drivers for every scored customer, using per‚Äërow SHAP‚Äëstyle contributions from XGBoost\n",
        "#   (leveraging `predict(..., pred_contribs=True)`).\n",
        "# ‚Ä¢ Drivers + their signed impact are appended to the output DataFrame returned by `test_model_on_new()`.\n",
        "# -------------------------------------------------\n",
        "# 0Ô∏è‚É£  Install & Imports\n",
        "# -------------------------------------------------\n",
        "!pip -q install scikit-learn xgboost joblib  # add shap if you prefer full SHAP plots\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import xgboost as xgb  # needed for pred_contribs\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    RocCurveDisplay,\n",
        ")\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1Ô∏è‚É£  Upload your training CSV\n",
        "# -------------------------------------------------\n",
        "print(\"üîº  Please choose the pre‚Äëprocessed dataset CSV (includes the target column).\")\n",
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise ValueError(\"No file uploaded ‚Äì¬†execution stopped.\")\n",
        "    DATA_PATH = next(iter(uploaded))\n",
        "except ModuleNotFoundError:\n",
        "    # If not in Colab, fall back to a local file path\n",
        "    DATA_PATH = \"Data final.csv\"\n",
        "    print(f\"Colab not detected ‚Äì¬†using {DATA_PATH}\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2Ô∏è‚É£  Load data + basic setup\n",
        "# -------------------------------------------------\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(f\"‚úÖ Loaded data¬†‚Üí {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
        "\n",
        "TARGET_COL = \"Churn\"          # <-- EDIT if your target has a different name\n",
        "ID_COLS     = [\"customerID\"]  # <-- Drop ID‚Äëlike columns as features\n",
        "\n",
        "# Binary‚Äëencode the target if needed\n",
        "y = df[TARGET_COL].map({\"Yes\": 1, \"No\": 0}) if df[TARGET_COL].dtype == \"O\" else df[TARGET_COL]\n",
        "X = df.drop(ID_COLS + [TARGET_COL], axis=1)\n",
        "\n",
        "# Detect feature types\n",
        "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
        "num_cols = X.select_dtypes(exclude=[\"object\", \"category\"]).columns.tolist()\n",
        "print(f\"üìä Numeric: {len(num_cols)}, Categorical: {len(cat_cols)}\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3Ô∏è‚É£  Preprocessing pipeline\n",
        "# -------------------------------------------------\n",
        "numeric_transformer = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline([\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", numeric_transformer, num_cols),\n",
        "    (\"cat\", categorical_transformer, cat_cols),\n",
        "])\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 4Ô∏è‚É£  Train / test split (stratified)\n",
        "# -------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "print(f\"üîπ Train: {X_train.shape}, üî∏ Test: {X_test.shape}\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 5Ô∏è‚É£  Model & hyper‚Äëparameter search (XGBoost)\n",
        "# -------------------------------------------------\n",
        "param_grid = {\n",
        "    \"learning_rate\":  [0.01, 0.05, 0.1],\n",
        "    \"max_depth\":      [3, 4, 5, 6, 8],\n",
        "    \"n_estimators\":   [300, 500, 800],\n",
        "    \"subsample\":      [0.7, 0.85, 1.0],\n",
        "    \"colsample_bytree\": [0.7, 0.85, 1.0],\n",
        "    \"gamma\":          [0, 1, 5],\n",
        "}\n",
        "\n",
        "xgb_base = XGBClassifier(\n",
        "    objective=\"binary:logistic\",\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=xgb_base,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=30,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=cv,\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "clf = Pipeline([\n",
        "    (\"pre\", preprocessor),\n",
        "    (\"model\", search),\n",
        "])\n",
        "\n",
        "print(\"üöÄ Training (this may take a few minutes)‚Ä¶\")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "best_model: XGBClassifier = clf.named_steps[\"model\"].best_estimator_\n",
        "print(f\"üèÜ Best XGB params: {clf.named_steps['model'].best_params_}\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 6Ô∏è‚É£  Evaluation (no hard accuracy threshold)\n",
        "# -------------------------------------------------\n",
        "print(\"\\n===== Evaluation =====\")\n",
        "\n",
        "y_pred  = clf.predict(X_test)\n",
        "y_proba = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "acc      = accuracy_score(y_test, y_pred)\n",
        "roc_auc  = roc_auc_score(y_test, y_proba)\n",
        "cm       = confusion_matrix(y_test, y_pred)\n",
        "report   = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"ROC‚ÄëAUC  : {roc_auc:.4f}\\n\")\n",
        "print(\"Classification Report:\\n\", report)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# ROC curve\n",
        "RocCurveDisplay.from_predictions(y_test, y_proba)\n",
        "plt.title(\"ROC Curve ‚Äì¬†XGBoost Churn Classifier\")\n",
        "plt.show()\n",
        "\n",
        "# Feature importance (top 20 ‚Äì global)\n",
        "enc = clf.named_steps[\"pre\"].named_transformers_[\"cat\"].named_steps[\"encoder\"]\n",
        "encoded_cat_features = enc.get_feature_names_out(cat_cols)\n",
        "all_feature_names = num_cols + list(encoded_cat_features)\n",
        "\n",
        "importances = best_model.feature_importances_\n",
        "imp_series = pd.Series(importances, index=all_feature_names).sort_values(ascending=False).head(20)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "imp_series[::-1].plot(kind=\"barh\")\n",
        "plt.title(\"Top‚Äë20 Feature Importances (XGBoost)\")\n",
        "plt.xlabel(\"Importance score\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 7Ô∏è‚É£  Save the trained pipeline\n",
        "# -------------------------------------------------\n",
        "joblib.dump(clf, \"churn_pipeline.pkl\")\n",
        "print(\"üíæ Pipeline saved as churn_pipeline.pkl (download via Files sidebar)\")\n",
        "\n",
        "# -------------------------------------------------\n",
        "# üîç Helper functions for per‚Äëcustomer drivers\n",
        "# -------------------------------------------------\n",
        "\n",
        "def _get_top_drivers(raw_df: pd.DataFrame, model_pipeline: Pipeline, top_n: int = 3):\n",
        "    \"\"\"Return lists of top‚ÄëN driver names & their signed impacts for each row in raw_df.\"\"\"\n",
        "\n",
        "    # Decompose pipeline\n",
        "    pre = model_pipeline.named_steps[\"pre\"]\n",
        "    booster: XGBClassifier = model_pipeline.named_steps[\"model\"].best_estimator_\n",
        "\n",
        "    # Build full feature name list (needs to mirror training order)\n",
        "    enc = pre.named_transformers_[\"cat\"].named_steps[\"encoder\"]\n",
        "    encoded_cat_features = enc.get_feature_names_out(cat_cols)\n",
        "    all_feats = num_cols + list(encoded_cat_features)\n",
        "\n",
        "    # Apply same preprocessing\n",
        "    X_trans = pre.transform(raw_df)\n",
        "\n",
        "    # Compute per‚Äërow contributions (SHAP values) via XGBoost booster\n",
        "    dmat = xgb.DMatrix(X_trans, feature_names=all_feats)\n",
        "    contribs = booster.get_booster().predict(dmat, pred_contribs=True)  # shape: (n_samples, n_features + 1)\n",
        "\n",
        "    driver_names = []\n",
        "    driver_impacts = []\n",
        "\n",
        "    for row in contribs:\n",
        "        row_contribs = row[:-1]  # exclude bias term\n",
        "        top_idx = np.argsort(np.abs(row_contribs))[::-1][:top_n]\n",
        "        driver_names.append([all_feats[i] for i in top_idx])\n",
        "        driver_impacts.append([float(row_contribs[i]) for i in top_idx])\n",
        "\n",
        "    return driver_names, driver_impacts\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 8Ô∏è‚É£  Interactively test on new data ‚Äì¬†returns drivers\n",
        "# -------------------------------------------------\n",
        "\n",
        "def test_model_on_new():\n",
        "    \"\"\"Upload a CSV *without* the target column ‚áí get churn predictions + top‚Äë3 drivers.\"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\"üîº  Upload a CSV with the same feature columns you used for training (no target column)‚Ä¶\")\n",
        "        new_upload = files.upload()\n",
        "        if not new_upload:\n",
        "            print(\"No file uploaded.\")\n",
        "            return None\n",
        "        new_path = next(iter(new_upload))\n",
        "    except ModuleNotFoundError:\n",
        "        print(\"Colab not detected ‚Äì¬†provide a file path instead of uploading.\")\n",
        "        return None\n",
        "\n",
        "    new_df = pd.read_csv(new_path)\n",
        "\n",
        "    preds = clf.predict(new_df)\n",
        "    probs = clf.predict_proba(new_df)[:, 1]\n",
        "\n",
        "    # --- Top‚Äë3 churn drivers ---\n",
        "    names_list, impacts_list = _get_top_drivers(new_df, clf, top_n=3)\n",
        "\n",
        "    out = new_df.copy()\n",
        "    out[\"PredictedChurn\"] = preds\n",
        "    out[\"ChurnProbability\"] = probs\n",
        "\n",
        "    # Unpack drivers into separate columns for clarity\n",
        "    for i in range(3):\n",
        "        out[f\"Driver{i+1}\"] = [names[i] if len(names) > i else None for names in names_list]\n",
        "        out[f\"Impact{i+1}\"] = [impacts[i] if len(impacts) > i else None for impacts in impacts_list]\n",
        "\n",
        "    print(\"\\nüîç  Predictions with top‚Äë3 churn drivers (first 10 rows):\")\n",
        "    display(out.head(10))\n",
        "    return out\n",
        "\n",
        "# ‚û°Ô∏è¬† After running all cells:\n",
        "# result_df = test_model_on_new()"
      ],
      "metadata": {
        "id": "6q48Ll-4ngUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model execution"
      ],
      "metadata": {
        "id": "BzdZ9_Bk6_Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Imports\n",
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import files\n",
        "import time\n",
        "\n",
        "# 2. Configuration\n",
        "PIPELINE_PATH = \"churn_pipeline.pkl\"\n",
        "os.environ[\"API_KEY\"] = \"AIzaSyAPrTyFXKJbs_wLLZcaC1JIkkZOCpT9Ieo\"\n",
        "client = genai.Client(api_key=os.environ[\"API_KEY\"])\n",
        "MODEL_NAME = \"gemini-2.0-flash\"\n",
        "\n",
        "# 3. Upload your new data CSV (no 'Churn' column)\n",
        "print(\"üîº Please upload your new data CSV (no 'Churn' column)‚Ä¶\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise RuntimeError(\"No file uploaded.\")\n",
        "data_path = next(iter(uploaded))\n",
        "\n",
        "# 4. Load pipeline and data\n",
        "pipeline = joblib.load(PIPELINE_PATH)\n",
        "df_new = pd.read_csv(data_path)\n",
        "print(f\"‚úÖ Loaded {df_new.shape[0]} rows, {df_new.shape[1]} columns from {data_path}\")\n",
        "\n",
        "# 5. Make predictions\n",
        "preds = pipeline.predict(df_new)\n",
        "probs = pipeline.predict_proba(df_new)[:, 1]\n",
        "\n",
        "# 6. Compute top-3 churn drivers\n",
        "def get_top_drivers(raw_df, pipeline, cat_cols, num_cols, top_n=3):\n",
        "    pre     = pipeline.named_steps[\"pre\"]\n",
        "    booster = pipeline.named_steps[\"model\"].best_estimator_\n",
        "    enc     = pre.named_transformers_[\"cat\"].named_steps[\"encoder\"]\n",
        "    encoded = enc.get_feature_names_out(cat_cols)\n",
        "    features = list(num_cols) + list(encoded)\n",
        "    Xt = pre.transform(raw_df)\n",
        "    dmat = xgb.DMatrix(Xt, feature_names=features)\n",
        "    contribs = booster.get_booster().predict(dmat, pred_contribs=True)\n",
        "    names, imps = [], []\n",
        "    for row in contribs:\n",
        "        vals = row[:-1]\n",
        "        idx  = np.argsort(np.abs(vals))[::-1][:top_n]\n",
        "        names.append([features[i] for i in idx])\n",
        "        imps.append([float(vals[i]) for i in idx])\n",
        "    return names, imps\n",
        "\n",
        "pre      = pipeline.named_steps[\"pre\"]\n",
        "num_cols = pre.transformers_[0][2]\n",
        "cat_cols = pre.transformers_[1][2]\n",
        "dnames, dimps = get_top_drivers(df_new, pipeline, cat_cols, num_cols, top_n=3)\n",
        "\n",
        "# 7. Assemble output DataFrame\n",
        "out = df_new.copy()\n",
        "out[\"PredictedChurn\"]    = preds\n",
        "out[\"ChurnProbability\"]  = probs\n",
        "if \"MonthlyCharges\" in out.columns:\n",
        "    out[\"LifetimeValueRisk\"] = np.where(preds==1, out[\"MonthlyCharges\"]*12, np.nan)\n",
        "for i in range(3):\n",
        "    out[f\"Driver{i+1}\"] = [names[i] if len(names)>i else None for names in dnames]\n",
        "    out[f\"Impact{i+1}\"] = [imps[i]  if len(imps)>i  else None for imps in dimps]\n",
        "\n",
        "# 8. Save & download CSV\n",
        "output_csv = \"churn_predictions_with_drivers.csv\"\n",
        "out.to_csv(output_csv, index=False)\n",
        "print(f\"üíæ Saved predictions to {output_csv}\")\n",
        "files.download(output_csv)\n",
        "\n",
        "# 9. Build prompt and call Gemini 2.0 Flash\n",
        "with open(output_csv, \"r\") as f:\n",
        "    csv_data = f.read()\n",
        "\n",
        "# Improved prompt with structural guidance and token constraints\n",
        "prompt = \"\"\"\n",
        "You are a customer-support co-pilot helping a new agent on a Telco call.\n",
        "Respond as if speaking directly to the agent in clear, conversational language.\n",
        "\n",
        "1. FIRST SECTION - OVERVIEW:\n",
        "   - Total number of customers in the dataset, churning and not\n",
        "   - Current churn rate (percentage of customers predicted to churn)\n",
        "   - Average annual Lifetime Value at risk across all churning customers\n",
        "\n",
        "2. SECOND SECTION - CUSTOMER DETAILS:\n",
        "   For each customer predicted to churn (PredictedChurn=1), provide:\n",
        "   - CustomerID\n",
        "   - Churn probability as a percentage\n",
        "   - Annual Lifetime Value at risk (dollar amount)\n",
        "   - The top three drivers of churn in order of impact\n",
        "   - For each driver, provide ONE specific, actionable suggestion the agent can say\n",
        "\n",
        "FORMAT YOUR RESPONSE WITH CLEAR HEADINGS AND BULLET POINTS.\n",
        "BE CONCISE AND FOCUS ON ACTIONABLE INSIGHTS, cover all the churning customers.\n",
        "\n",
        "Here's the customer data:\n",
        "\"\"\" + csv_data\n",
        "\n",
        "print(\"ü§ñ Generating summary via Gemini 2.0 Flash‚Ä¶\")\n",
        "\n",
        "# Configure for more complete responses with chunking to handle token limits\n",
        "def generate_with_retry(prompt, max_attempts=3):\n",
        "    for attempt in range(max_attempts):\n",
        "        try:\n",
        "            response = client.models.generate_content(\n",
        "                model=MODEL_NAME,\n",
        "                contents=prompt,\n",
        "                config=types.GenerateContentConfig(\n",
        "                    temperature=0.2,\n",
        "                    max_output_tokens=4096,  # Increased token limit\n",
        "                    top_p=0.95,\n",
        "                    top_k=40\n",
        "                )\n",
        "            )\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
        "            time.sleep(2)  # Brief pause before retry\n",
        "    return \"Error: Failed to generate complete response after multiple attempts.\"\n",
        "\n",
        "# Generate and print the summary\n",
        "summary = generate_with_retry(prompt)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CUSTOMER CHURN ANALYSIS\")\n",
        "print(\"=\"*50 + \"\\n\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FzQXpmFr7CtL",
        "outputId": "c7509e67-0163-4627-b3af-78f1e85fc295"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîº Please upload your new data CSV (no 'Churn' column)‚Ä¶\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0a59219c-1c86-4b2d-9ff3-ce5a2a48f5fa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0a59219c-1c86-4b2d-9ff3-ce5a2a48f5fa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Data sample.csv to Data sample (4).csv\n",
            "‚úÖ Loaded 19 rows, 29 columns from Data sample (4).csv\n",
            "üíæ Saved predictions to churn_predictions_with_drivers.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e757a199-8c5f-4020-9d7c-3ead50867592\", \"churn_predictions_with_drivers.csv\", 6396)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Generating summary via Gemini 2.0 Flash‚Ä¶\n",
            "\n",
            "==================================================\n",
            "CUSTOMER CHURN ANALYSIS\n",
            "==================================================\n",
            "\n",
            "Okay, here's the breakdown of the customer data and some actionable insights you can use on the call.\n",
            "\n",
            "**FIRST SECTION - OVERVIEW**\n",
            "\n",
            "*   **Total Customers:** Based on the data provided, we have 20 customers.\n",
            "*   **Churn Prediction:** 5 customers are predicted to churn (PredictedChurn = 1).\n",
            "*   **Churn Rate:** 25% of these customers are predicted to churn.\n",
            "*   **Average Lifetime Value at Risk:** The average annual Lifetime Value at risk across all churning customers is $900.08.\n",
            "\n",
            "**SECOND SECTION - CUSTOMER DETAILS**\n",
            "\n",
            "Here's a breakdown of each customer predicted to churn, along with specific suggestions for you:\n",
            "\n",
            "*   **Customer ID:** 7590-VHVEG\n",
            "    *   **Churn Probability:** 65.06%\n",
            "    *   **Lifetime Value at Risk:** $358.20\n",
            "    *   **Top 3 Churn Drivers:**\n",
            "        1.  **Contract (Month-to-month):** \"I see you're on a month-to-month contract. We have some great deals on longer-term contracts that could save you money and provide more price stability. Would you be interested in hearing about those?\"\n",
            "        2.  **Tenure:** \"I notice you've only been with us for a short time. We want to make sure you have a great experience. Is there anything we can do to improve your service or address any concerns you might have?\"\n",
            "        3.  **TotalCharges:** \"I understand that the total charges may be a concern. Let's review your current plan and see if there are any adjustments we can make to better align with your budget while still meeting your needs.\"\n",
            "*   **Customer ID:** 9237-HQITU\n",
            "    *   **Churn Probability:** 57.45%\n",
            "    *   **Lifetime Value at Risk:** $848.40\n",
            "    *   **Top 3 Churn Drivers:**\n",
            "        1.  **Contract (Month-to-month):** \"I see you're on a month-to-month contract. We have some great deals on longer-term contracts that could save you money and provide more price stability. Would you be interested in hearing about those?\"\n",
            "        2.  **Tenure:** \"I notice you've only been with us for a short time. We want to make sure you have a great experience. Is there anything we can do to improve your service or address any concerns you might have?\"\n",
            "        3.  **OnlineSecurity_No:** \"I see you don't have online security. We can add that to your plan for just a small monthly fee. It will protect your devices from viruses and malware.\"\n",
            "*   **Customer ID:** 9305-CDSKC\n",
            "    *   **Churn Probability:** 80.84%\n",
            "    *   **Lifetime Value at Risk:** $1195.80\n",
            "    *   **Top 3 Churn Drivers:**\n",
            "        1.  **Contract (Month-to-month):** \"I see you're on a month-to-month contract. We have some great deals on longer-term contracts that could save you money and provide more price stability. Would you be interested in hearing about those?\"\n",
            "        2.  **avg_monthly_spend:** \"I see that your average monthly spend is high. Let's review your current plan and see if there are any adjustments we can make to better align with your budget while still meeting your needs.\"\n",
            "        3.  **InternetService_Fiber optic:** \"I see you have Fiber Optic internet. We can offer you a discount on your internet service if you sign up for a longer-term contract.\"\n",
            "*   **Customer ID:** 7892-POOKP\n",
            "    *   **Churn Probability:** 50.92%\n",
            "    *   **Lifetime Value at Risk:** $1257.60\n",
            "    *   **Top 3 Churn Drivers:**\n",
            "        1.  **Contract (Month-to-month):** \"I see you're on a month-to-month contract. We have some great deals on longer-term contracts that could save you money and provide more price stability. Would you be interested in hearing about those?\"\n",
            "        2.  **TechSupport_No:** \"I see you don't have tech support. We can add that to your plan for just a small monthly fee. It will give you access to our expert technicians who can help you with any technical issues you may have.\"\n",
            "        3.  **MonthlyCharges:** \"I see that your monthly charges are high. Let's review your current plan and see if there are any adjustments we can make to better align with your budget while still meeting your needs.\"\n",
            "*   **Customer ID:** 0280-XJGEX\n",
            "    *   **Churn Probability:** 51.37%\n",
            "    *   **Lifetime Value at Risk:** $1244.40\n",
            "    *   **Top 3 Churn Drivers:**\n",
            "        1.  **Contract (Month-to-month):** \"I see you're on a month-to-month contract. We have some great deals on longer-term contracts that could save you money and provide more price stability. Would you be interested in hearing about those?\"\n",
            "        2.  **Tenure:** \"I notice you've been with us for a long time. We want to make sure you have a great experience. Is there anything we can do to improve your service or address any concerns you might have?\"\n",
            "        3.  **MonthlyCharges:** \"I see that your monthly charges are high. Let's review your current plan and see if there are any adjustments we can make to better align with your budget while still meeting your needs.\"\n",
            "\n",
            "Remember to be empathetic and listen to the customer's concerns. Use these suggestions as a starting point and tailor your approach to each individual. Good luck!\n"
          ]
        }
      ]
    }
  ]
}